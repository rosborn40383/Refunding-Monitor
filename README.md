# Refunding-Monitor
Just some general files of the setup of updating prices and creating a working macro for data population. The idea is to firstly use the CUSIP's to update bond prices (Bloomberg data), then create a macro in excel for populating data.
Currently includes my TM3 data scraper along with an update python file that takes the newest data, adds it to a master csv, and updates the excel spreadsheet connections. Some code may seem inefficient or there could be easier ways to do it, however I am in a working enviroment where the person requesting this data and I have different systems so I have to make sure it will work for both of us. So I am running on windows 10 using office 2016 (32-bit) while using Python 3.9.12 since i need these versions for other duties. The person requesting this information is on Office 365 (64-bit) and has no access to python or else I would have the code directly apply changes to the excel sheet. 

Steps for updating the tax-exempt table data: AFTER the tm3 data scraper has ran (not the one in this repository), you can run the refunding_update python file to grab the most recent data and add it to the master csv. The master csv is connected to the refunding monitor excel sheet so when the data gets refreshed, the tax-exempt macro will be up to date.

Steps for updating BVAL/MMD prices: Firstly, BVAL prices require access to Bloomberg and curerntly does not utilize any API (plan to in the future). So if you have a list of CUSIP's, run this list through the add-muni python file to add the word muni to them or else Bloomberg will not recognize the municipal bond CUSIP. with this list just us the built in excel Bloomberg add-in to gather the most recent prices and copy/paste to refunding moniitor. (I am trying to make this easier w/ no copy and pasting.
Secondly, the MMD prices are tricky to consistently update. These prices are gathered from the TM3 website using the mmd scraper python file. This goes through each CUSIP list in a CSV folder, categorizes it based on the name of the csv, and scrapes the most recent data for that exact CUSIP. I have added some error handling since not all CUSIP data is shown on the website. This WILL take a while to run and I feel I have made it as efficient as I can considering that it takes a newpayload for each CUSIP and has to go to a new URL for each one. This has taken about 100 minutes each time and I wouldn't recommend running it daily. After your data is scraped, you need to pull all data of that date from the SQLite(3) databse and organize it by category. Then it is just a matter of copy/pasting into the refunding monitor sheet.

I am still working on improvements for efficiency and trying to automate some of these proceeses. Currently have the refunding update file being ran through a bat file daily so the excel sheet tax-exempt data is automated. 
