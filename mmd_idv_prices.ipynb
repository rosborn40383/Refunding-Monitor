{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37db997a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Opening session...\n",
      "DEBUG:urllib3.util.retry:Converted retries value: 3 -> Retry(total=3, connect=None, read=None, redirect=None, status=None)\n",
      "INFO:root:Scraping CUSIP 49151FZS2 in category Agency...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scrape_cusip_data() missing 1 required positional argument: 'cusips_to_scrape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 112>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cusip \u001b[38;5;129;01min\u001b[39;00m cusips_to_scrape:\n\u001b[0;32m    104\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScraping CUSIP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcusip\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in category \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m     \u001b[43mscrape_cusip_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcusip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Close the connection after processing\u001b[39;00m\n\u001b[0;32m    108\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mTypeError\u001b[0m: scrape_cusip_data() missing 1 required positional argument: 'cusips_to_scrape'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "\n",
    "LOGIN_URL = 'https://www.tm3.com/homepage/login.jsf'\n",
    "CUSIP_EVAL_URL_TEMPLATE = 'https://www.tm3.com/mvsearch/cusipEvalHistoryContent.jsf?cusipId={}'\n",
    "USERNAME = 'T28395M63'\n",
    "PASSWORD = 'HOWARD'\n",
    "\n",
    "DB_FILE = 'mmd.db'\n",
    "\n",
    "def create_database_table(cursor):\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS evaluation_history (\n",
    "            cusip TEXT,\n",
    "            date TEXT,\n",
    "            price TEXT,\n",
    "            category TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "def login(session):\n",
    "    payload = {}\n",
    "    result = session.get(LOGIN_URL, verify=False)\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    \n",
    "    hidden_inputs = soup.find_all('input', type='hidden')\n",
    "    for hidden_input in hidden_inputs:\n",
    "        name = hidden_input.get('name')\n",
    "        payload[name] = hidden_input.get('value')\n",
    "    \n",
    "    payload['username'] = USERNAME\n",
    "    payload['password'] = PASSWORD\n",
    "    payload['loginButton'] = 'Login'\n",
    "    \n",
    "    logger.debug('Payload is %s' % payload)\n",
    "    logger.info('Attempting to login...')\n",
    "    \n",
    "    login_response = session.post(LOGIN_URL, data=payload, timeout=30.0)\n",
    "    \n",
    "    if \"Invalid login\" in login_response.text:\n",
    "        raise Exception(\"Login failed. Check credentials.\")\n",
    "    else:\n",
    "        logger.info(\"Login successful.\")\n",
    "\n",
    "def scrape_cusip_data(cusip, category, session, cursor, conn, cusips_to_scrape):\n",
    "    base_url = CUSIP_EVAL_URL_TEMPLATE.format(cusip)\n",
    "\n",
    "    logger.info(f'Logging in before scraping CUSIP {cusip} at {base_url}...')\n",
    "    logger.debug(f'Base URL: {base_url}')\n",
    "\n",
    "    login(session)\n",
    "\n",
    "    logger.info(f'Scraping CUSIP {cusip} at {base_url}...') #Debug messages about which CUSIP is being scraped\n",
    "    response = session.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    config2a_div = soup.find('div', class_='config2a') #For my specific HTML\n",
    "    groupA_div = config2a_div.find('div', class_='groupA') if config2a_div else None\n",
    "    group_a_table = groupA_div.find('table', class_='data') if groupA_div else None\n",
    "\n",
    "    data = []\n",
    "    if group_a_table:\n",
    "        for row in group_a_table.select('tbody tr'):\n",
    "            cells = row.find_all('td')\n",
    "            date = cells[0].get_text(strip=True)\n",
    "            price = cells[1].get_text(strip=True)\n",
    "\n",
    "            cursor.execute('''\n",
    "                INSERT INTO evaluation_history (cusip, date, price, category)\n",
    "                VALUES (?, ?, ?, ?)\n",
    "            ''', (cusip, date, price, category))\n",
    "\n",
    "            conn.commit()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    with requests.Session() as session:\n",
    "        logging.info('Opening session...')\n",
    "        session.mount('https://', HTTPAdapter(max_retries=3))\n",
    "        session.verify = False  # Set to True if SSL verification is required\n",
    "\n",
    "        # Establish a connection and create a cursor\n",
    "        conn = sqlite3.connect(DB_FILE)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        create_database_table(cursor)\n",
    "\n",
    "        # Specify the single file you want to test (e.g., \"Agency.csv\")\n",
    "        csv_file_path = 'J:/Python/ksm/ksm2023/CSV/KSU.csv'\n",
    "\n",
    "        category = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "        cusips_to_scrape = pd.read_csv(csv_file_path, usecols=['CUSIP'], index_col='CUSIP').index.tolist()\n",
    "\n",
    "        for cusip in cusips_to_scrape:\n",
    "            logging.info(f'Scraping CUSIP {cusip} in category {category}...')\n",
    "            scrape_cusip_data(cusip, category, session, cursor, conn, cusips_to_scrape)\n",
    "\n",
    "        # Close the connection after processing\n",
    "        conn.close()\n",
    "\n",
    "    logging.info('Done...')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c3b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
