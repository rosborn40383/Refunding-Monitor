{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG) #All this is doing is creating debugging messages incase something goes wrong\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "\n",
    "LOGIN_URL = 'https://www.tm3.com/homepage/login.jsf'\n",
    "CUSIP_EVAL_URL_TEMPLATE = 'https://www.tm3.com/mvsearch/cusipEvalHistoryContent.jsf?cusipId={}'\n",
    "USERNAME = 'REDACTED'\n",
    "PASSWORD = 'REDACTED'\n",
    "\n",
    "DB_FILE = 'mmd.db'\n",
    "\n",
    "\n",
    "\n",
    "def create_database_table(cursor):\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS evaluation_history (\n",
    "            cusip TEXT,\n",
    "            date TEXT,\n",
    "            price TEXT,\n",
    "            category TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "def login(session):\n",
    "    payload = {}\n",
    "    result = session.get(LOGIN_URL, verify=False)\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    \n",
    "    hidden_inputs = soup.find_all('input', type='hidden')\n",
    "    for hidden_input in hidden_inputs:\n",
    "        name = hidden_input.get('name')\n",
    "        payload[name] = hidden_input.get('value')\n",
    "    \n",
    "    payload['username'] = USERNAME\n",
    "    payload['password'] = PASSWORD\n",
    "    payload['loginButton'] = 'Login'\n",
    "    \n",
    "    logger.debug('Payload is %s' % payload)\n",
    "    logger.info('Attempting to login...')\n",
    "    \n",
    "    login_response = session.post(LOGIN_URL, data=payload, timeout=30.0)\n",
    "    \n",
    "    if \"Invalid login\" in login_response.text:\n",
    "        raise Exception(\"Login failed. Check credentials.\")\n",
    "    else:\n",
    "        logger.info(\"Login successful.\")\n",
    "        \n",
    "def validate_cusip(cusip):\n",
    "    # Validate CUSIP format to ensure that nothing unexpected or malicious is scraped\n",
    "    if not re.match(r'^[0-9A-Za-z]{9}$', cusip):\n",
    "        raise ValueError('Invalid CUSIP format')\n",
    "\n",
    "def scrape_cusip_data(cusip, category, session, cursor, conn, cusips_to_scrape):\n",
    "    base_url = CUSIP_EVAL_URL_TEMPLATE.format(cusip)\n",
    "\n",
    "    logger.info(f'Logging in before scraping CUSIP {cusip} at {base_url}...')\n",
    "    logger.debug(f'Base URL: {base_url}')\n",
    "\n",
    "    login(session)\n",
    "\n",
    "    logger.info(f'Scraping CUSIP {cusip} at {base_url}...') #Debug messages about which CUSIP is being scraped\n",
    "    response = session.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    config2a_div = soup.find('div', class_='config2a') #For my specific HTML\n",
    "    groupA_div = config2a_div.find('div', class_='groupA') if config2a_div else None\n",
    "    group_a_table = groupA_div.find('table', class_='data') if groupA_div else None\n",
    "\n",
    "    data = []\n",
    "    if group_a_table:\n",
    "        # Extract the first row (most recent date)\n",
    "        row = group_a_table.select_one('tbody tr')\n",
    "        cells = row.find_all('td')\n",
    "        date = cells[0].get_text(strip=True)\n",
    "        price = cells[1].get_text(strip=True)\n",
    "\n",
    "        cursor.execute('''\n",
    "            INSERT INTO evaluation_history (cusip, date, price, category)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        ''', (cusip, date, price, category))\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    with requests.Session() as session:\n",
    "        logging.info('Opening session...')\n",
    "        session.mount('https://', HTTPAdapter(max_retries=3))\n",
    "        session.verify = False  # Set to True if SSL verification is required\n",
    "\n",
    "        # Establish a connection and create a cursor\n",
    "        conn = sqlite3.connect(DB_FILE)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        create_database_table(cursor)\n",
    "\n",
    "        # Specify the single file you want to test (e.g., \"Agency.csv\")\n",
    "        csv_file_path = 'J:/Python/ksm/ksm2023/CSV/KSU.csv'\n",
    "\n",
    "        category = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "        cusips_to_scrape = pd.read_csv(csv_file_path, usecols=['CUSIP'], index_col='CUSIP').index.tolist()\n",
    "\n",
    "        for cusip in cusips_to_scrape:\n",
    "            logging.info(f'Scraping CUSIP {cusip} in category {category}...')\n",
    "            scrape_cusip_data(cusip, category, session, cursor, conn, cusips_to_scrape)\n",
    "\n",
    "        # Close the connection after processing\n",
    "        conn.close()\n",
    "\n",
    "    logging.info('Done...')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
